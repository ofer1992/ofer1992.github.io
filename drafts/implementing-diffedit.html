<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>Implementing DiffEdit</title>
        <link rel="stylesheet" href="/theme/css/custom.css" />
        <meta name="description" content="Today we'll work on lesson 11's homework: implementing the DiffEdit paper. In the lesson we went over the paper, and saw that the method is fairly..." />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Integrably Sorry</a></h1>
                <nav><ul>
                    <li><a href="/pages/about.html">About</a></li>
                    <li class="active"><a href="/category/dailies.html">Dailies</a></li>
                    <li><a href="/category/life.html">Life</a></li>
                    <li><a href="/category/math.html">Math</a></li>
                    <li><a href="/category/programming.html">Programming</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/drafts/implementing-diffedit.html" rel="bookmark"
           title="Permalink to Implementing DiffEdit">Implementing DiffEdit</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2024-07-24T14:55:00+03:00">
                Published: Wed 24 July 2024
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ofer-yehuda.html">Ofer Yehuda</a>
        </address>
<p>In <a href="/category/dailies.html">Dailies</a>.</p>

</footer><!-- /.post-info -->      <p>Today we'll work on <a href="https://course.fast.ai/Lessons/lesson11.html">lesson 11's</a> homework: implementing the <a href="https://arxiv.org/pdf/2210.11427">DiffEdit</a> paper. In the lesson we went over the paper, and saw that the method is fairly straightforward. In fact, I was tempted to skip this, but then I realized this is classic case of the illusion of knowledge: I think it's easy to implement, but when it comes to it, there are a lot of small details I am not sure about. It's like thinking a song is easy to play on the piano, but when you actually try to play it you see the the chord changes are actually not that familiar and you stutter.</p>
<p>We start with the manual pipeline code from one of the previous lectures. It's quite short</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">CLIPTextModel</span><span class="p">,</span> <span class="n">CLIPTokenizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoencoderKL</span><span class="p">,</span> <span class="n">UNet2DConditionModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">diffusers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LMSDiscreteScheduler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm.auto</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="n">prompts</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;a photograph of an astronaut riding a horse&#39;</span><span class="p">,</span>
    <span class="s1">&#39;an oil painting of an astronaut riding a horse in the style of grant wood&#39;</span>
<span class="p">]</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_inference_steps</span> <span class="o">=</span> <span class="mi">70</span>
<span class="n">guidance_scale</span> <span class="o">=</span> <span class="mf">7.5</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">beta_start</span><span class="p">,</span><span class="n">beta_end</span> <span class="o">=</span> <span class="mf">0.00085</span><span class="p">,</span><span class="mf">0.012</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CLIPTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-large-patch14&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">text_encoder</span> <span class="o">=</span> <span class="n">CLIPTextModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai/clip-vit-large-patch14&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">vae</span> <span class="o">=</span> <span class="n">AutoencoderKL</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;stabilityai/sd-vae-ft-ema&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">unet</span> <span class="o">=</span> <span class="n">UNet2DConditionModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;CompVis/stable-diffusion-v1-4&quot;</span><span class="p">,</span> <span class="n">subfolder</span><span class="o">=</span><span class="s2">&quot;unet&quot;</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LMSDiscreteScheduler</span><span class="p">(</span><span class="n">beta_start</span><span class="o">=</span><span class="n">beta_start</span><span class="p">,</span> <span class="n">beta_end</span><span class="o">=</span><span class="n">beta_end</span><span class="p">,</span> <span class="n">beta_schedule</span><span class="o">=</span><span class="s2">&quot;scaled_linear&quot;</span><span class="p">,</span> <span class="n">num_train_timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">text_enc</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">maxlen</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">maxlen</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text_encoder</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mk_img</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">((</span><span class="n">image</span><span class="o">*</span><span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">mk_samples</span><span class="p">(</span><span class="n">prompts</span><span class="p">,</span> <span class="n">g</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">70</span><span class="p">):</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text_enc</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
    <span class="n">uncond</span> <span class="o">=</span> <span class="n">text_enc</span><span class="p">([</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">bs</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">uncond</span><span class="p">,</span> <span class="n">text</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">seed</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">latents</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span> <span class="n">unet</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">height</span><span class="o">//</span><span class="mi">8</span><span class="p">,</span> <span class="n">width</span><span class="o">//</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">half</span><span class="p">()</span> <span class="o">*</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">init_noise_sigma</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ts</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span><span class="p">)):</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">scale_model_input</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">ts</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="n">u</span><span class="p">,</span><span class="n">t</span> <span class="o">=</span> <span class="n">unet</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">emb</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">u</span> <span class="o">+</span> <span class="n">g</span><span class="o">*</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">u</span><span class="p">)</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">ts</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span><span class="o">.</span><span class="n">prev_sample</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="k">return</span> <span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mf">0.18215</span> <span class="o">*</span> <span class="n">latents</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">mk_samples</span><span class="p">(</span><span class="n">prompts</span><span class="p">)</span>
</code></pre></div>

<p>Some imports, loading models, some hyperparams. Inference takes place in <code>mk_samples</code>, and this is where we'll introduce our changes.</p>
<h2>How DiffEdit works</h2>
<p>So what's the idea behind DiffEdit? we have the following chart from the paper</p>
<p style="width:100%; margin:auto">
  <img src="/images/diffedit_flow.png" />
</p>
<!--![[diffedit_flow.png]]-->

<p>The notation seems to be:
- <span class="math">\(R\)</span> - the reference text, ie the text that describes the original image.
- <span class="math">\(Q\)</span> - the query, ie what describes the new image we wish to have.
- <span class="math">\(x_{t}\)</span> - the original image in diffusion step <span class="math">\(t\)</span>.
- <span class="math">\(y_t\)</span> - the modified image in diffusion step <span class="math">\(t\)</span>.</p>
<h3>Step 1: Compute a mask</h3>
<p>In the first step, we introduce noise into the image. We then feed the noised image to the model with the two different prompts, once with <span class="math">\(R\)</span> and once with <span class="math">\(Q\)</span>. We then look at the difference between the predicted noises. The idea is, where these noises differ is where a horse differs from a zebra. For example, for a pixel in the background it doesn't matter whether the animal is a horse or a zebra, therefore the noise there will be the same across the queries. On the other hand, a pixel on the animal's body does depend on the query: a horse will be reddish while a zebra black/white.</p>
<p>The mask is binarized, that means that we choose a threshold and every pixel where the difference is above that threshold becomes <code>True</code>.</p>
<p><strong>Qs:</strong>
- How much noise is introduced? what step of the diffusion do we reach?
- How is the noise introduced? probably the scheduler
- Do we compute one denoising step? I think so
- How is the difference normalized?</p>
<p>Let's implement this part. Stuff to do:
- Load an image
- Encode it using vae (stable diffusion acts in latent space)
- Noise it with scheduler
    - generate standard gaussian noise
    - choose a timestep</p>
<hr>

<p>Yep, this is definitely good practice, so I'm going to be fairly descriptive. For loading an image, we first use the PIL library:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</code></pre></div>

<p>To convert it to a tensor we use the <code>torchvision</code> library</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>

<span class="n">im_t</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()(</span><span class="n">im</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">))</span>
</code></pre></div>

<p><code>im_t</code> is now a <code>float32</code> tensor with shape <code>(3, 512, 512)</code> (so color channels are the first index as is torch's convention). The values range from 0 to 1. This is important as the autoencoder expects images to be within -1 and 1, so we have to scale the image</p>
<div class="highlight"><pre><span></span><code><span class="n">im_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">im_t</span> <span class="o">-</span> <span class="mf">.5</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
</code></pre></div>

<p>Now to encode using the autoencoder, it's fairly straightforward.</p>
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">enc</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">im_t</span><span class="p">)</span><span class="o">.</span><span class="n">latent_dist</span><span class="o">.</span><span class="n">mean</span>
    <span class="n">dec</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">enc</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span>
</code></pre></div>

<p>We look at the original vs the decoded for sanity (I found some bugs that way)</p>
<!--![[omri_orig.png]]![[omri_dec.png]]-->
<div style="display: flex; justify-content: center;">
  <div style="text-align: center; margin: 0 10px;">
    <img src="/images/omri_orig.png" alt="Original Image" style="max-width: 100%; height: auto;">
    <div>Original</div>
  </div>
  <div style="text-align: center; margin: 0 10px;">
    <img src="/images/omri_dec.png" alt="Decoded Image" style="max-width: 100%; height: auto;">
    <div>Decoded</div>
  </div>
</div>
<p>there is a twist though: SD scales the encoding so we need to remember to scale it down and up.</p>
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">enc</span> <span class="o">=</span>  <span class="mf">0.18215</span> <span class="o">*</span> <span class="n">vae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">im_t</span><span class="p">)</span><span class="o">.</span><span class="n">latent_dist</span><span class="o">.</span><span class="n">mean</span>
    <span class="n">dec</span> <span class="o">=</span> <span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mf">0.18215</span> <span class="o">*</span> <span class="n">enc</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span>
</code></pre></div>

<p>We're going to noise it with the scheduler. </p>
<div class="highlight"><pre><span></span><code><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">enc</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">step</span> <span class="o">=</span> <span class="mi">64</span> <span class="c1"># the diffusion step we take</span>
<span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span><span class="p">[</span><span class="n">step</span><span class="p">]])</span>
<span class="n">noisy_image</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">add_noise</span><span class="p">(</span><span class="n">enc</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
</code></pre></div>

<p>If we decode the noisy image we get back</p>
<!--![[omri_noisy.png]]-->
<p style="width:50%; margin:auto">
  <img src="/images/omri_noisy.png" />
</p>
<p>We will figure out later a proper step choice. Now for the denoising step, this is where things get fuzzy and uncertain. What I did so far is</p>
<div class="highlight"><pre><span></span><code><span class="n">inp</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">scale_model_input</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">noisy_image</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">r</span><span class="p">,</span><span class="n">q</span> <span class="o">=</span> <span class="n">unet</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">emb</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<p><code>r</code> and <code>q</code> should be the predicted noises. The question I have now is whether we can visualize the mask. The tricky part is it's in the latent space, so the mapping the pixels is not straightforward. Maybe it's time to read the paper.</p>
<blockquote>
<p>In our algorithm, we use a Gaussian noise with strength 50% (see analysis in Appendix A.1), remove extreme values in noise predictions and stabilize the effect by averaging spatial differences over a set of <code>n</code> input noises, with <code>n=10</code> in our default configuration. The result is then rescaled to the range [0, 1], and binarized with a threshold, which we set to 0.5 by default.</p>
</blockquote>
<p>Here's the modifications I did based on that (untouched lines omitted)</p>
<div class="highlight"><pre><span></span><code><span class="n">n_noise</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">mask_thresh</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># change noise to have n_noise copies</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_noise</span><span class="p">,</span> <span class="o">*</span><span class="n">enc</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>

<span class="c1"># change emb to have n_noise copies</span>
<span class="n">emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">emb</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span><span class="o">...</span><span class="p">]]</span> <span class="o">*</span> <span class="n">n_noise</span> <span class="o">+</span> <span class="p">[</span><span class="n">emb</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span><span class="o">...</span><span class="p">]]</span> <span class="o">*</span> <span class="n">n_noise</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">r</span><span class="p">,</span><span class="n">q</span> <span class="o">=</span> <span class="n">unet</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">emb</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># calculate mask according to description</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">r</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">-</span> <span class="n">mask</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">mask</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">mask</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">&gt;</span> <span class="n">mask_thresh</span>
</code></pre></div>

<p>Looking at the masks, it kinda looks reasonable, pixels are located next to the hands, but it's quite sparse. I guess we'll see.</p>
<!--![[mask_channels.png]]-->
<p style="width:80%; margin:auto">
  <img src="/images/mask_channels.png" />
</p>

<p>Okay, on to step two.</p>
<h3>Step 2: Encode with DDIM until encoding ratio r</h3>
<p>What the hell is <span class="math">\(r\)</span>? from the paper</p>
<blockquote>
<p>In the remainder of the paper, we parameterize the timestep t to be between 0 and 1, so that t = 1 corresponds to T steps of diffusion in the original formulation.</p>
<p>as proposed by Song et al. (2021), we can also use this ODE to encode an image <span class="math">\(x_0\)</span> onto a latent variable <span class="math">\(x_r\)</span> for a timestep <span class="math">\(r\leq 1\)</span></p>
</blockquote>
<p>and</p>
<blockquote>
<p>In the remainder of the paper, we refer to this encoding process as DDIM encoding, we denote the corresponding function that maps <span class="math">\(x_0\)</span> to <span class="math">\(x_r\)</span> as <span class="math">\(E_r\)</span> and refer to the variable <span class="math">\(r\)</span> as the encoding
ratio.</p>
</blockquote>
<p>So <span class="math">\(r\)</span> is the time step. I wonder if the mask phase and decoding phase have to be identical? probably not, since the "strength" of the noise is 50%, if only I knew what that means.</p>
<hr>

<p>Let's get things straight for a second, what are all these letters standing for? according to the paper, the forward diffusion is defined as
</p>
<div class="math">$$
x_t = \sqrt{\alpha_t}x_0+\sqrt{1-\alpha_t}\varepsilon
$$</div>
<p>
where <span class="math">\(\varepsilon\sim \mathcal N(0, I)\)</span>. What would be 50% strength then? when <span class="math">\(\alpha_t=1-\frac{1}{2^2}\)</span>? </p>
<hr>

<p>Putting that aside for now, let's get the second step implemented.  Working on this</p>
<div class="highlight"><pre><span></span><code><span class="n">r</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">enc_step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">steps</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">r</span><span class="p">))</span>
<span class="n">enc_step2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span><span class="p">[:</span><span class="n">enc_step</span><span class="p">]])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">enc_r</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">add_noise</span><span class="p">(</span><span class="n">enc</span><span class="p">,</span> <span class="n">noise</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">enc_step2</span><span class="p">)</span>
<span class="c1"># latents = latents.to(&quot;cuda&quot;).half() * scheduler.init_noise_sigma</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ts</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span><span class="p">[</span><span class="n">enc_step</span><span class="p">:])):</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">scale_model_input</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">ts</span><span class="p">)</span>
</code></pre></div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://github.com/ofer1992">github</a></li>
                            <li><a href="https://x.com/oferyehuda">twitter</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>